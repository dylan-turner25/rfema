---
title: "rfema: Getting Started"
author: "Dylan Turner"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
# output:
#  github_document:
#    toc: true
#    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{rfema: Getting Started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

library(knitr)
library(dplyr)
remotes::install_github("dylan-turner25/rfema", force = T) # make sure package is most recent version
library(rfema)
```

## Introduction

This vignette provides a brief overview on using the `rfema` package to obtain data from the Open FEMA API. The rest of this vignette covers how to install the package, followed by examples on using the package to obtain data for various objectives. 

## Installation
Right now, the best way to install and use the `rfema` package is by installing directly from GitHub using `remotes::install_github("dylan-turner25/rfema")`. The FEMA API does not require and API key, meaning no further setup steps need be taken to start using the package

## Available Datasets
For those unfamiliar with the data sets available through the FEMA API, a good starting place is to visit the [FEMA API documentation page](https://www.fema.gov/about/openfema/data-sets). However, if you are already familiar with the data and want to quickly reference the data set names or another piece of meta data, using the `fema_data_sets()` function to obtain a tibble of available data sets along with associated meta data is a convenient option.
```{r, cache = T}
# store the avaliable data sets as an object in your R environment that can be referenced later
data_sets <- fema_data_sets() 

# view data 
data_sets

```


## Example Workflow
Once we know what data set we want to access, or perhaps if we want to know more about what data is available in a given data set, we can use the `fema_data_fields()` function to get a look at the available data fields in a given data set by setting the "data_set" parameter to one of the "name" columns in the data frame returned by the `fema_data_sets()` function.
```{r,cache=T}
# obtain all the data fields for the NFIP Policies data set
df <- fema_data_fields(data_set = "fimaNfipPolicies")

# Note: the data set field is not case sensative, meaning you do not need to 
# use camel case names despite that being the convention in the FEMA documentation.
df <- fema_data_fields(data_set = "fimanfippolicies")

# view the data fields 
df

```



The FEMA API limits the number of records that can be returned in a single query to 1000, meaning if we want more observations than that, a loop is necessary to iterate over multiple API calls. The `open_fema` function handles this process automatically, but by default will issue a warning letting you know how many records match your criteria and how many API calls it will take to retrieve all those records and ask you to confirm the request before it starts retrieving data (this behavior can be turned off by setting the `ask_before_call` argument to `FALSE`). Additionally an estimated time will be issued to give you a sense of how long it will take to complete the request. For example, requesting the entire NFIP claims data set via `open_fema(data_set = "fimaNfipClaims")` will yield the following output in the R console.

```{r, echo = F}
time <- rfema:::time_iterations("fimanfipclaims",2565)
message(rfema:::get_status_message(n_records = 2564279, iterations = 2565,top_n = NULL, estimated_time = time))
print(noquote("1 - Yes, get that data!, 0 - No, let me rethink my API call: "))
```

Note that the estimated time is based on network conditions at the initial time the call is being made and may not be accurate for large data requests that take long enough for network conditions to potential change significantly during the request. As an aside, for large data requests, like downloading the entire data set, it will usually be faster to perform a bulk download using the `bulk_dl` function. 


Alternatively, we could specify the top_n argument to limit the number of records returned. Specifying top_n greater than 1000 will initiate the same message letting you know how many iterations it will take to get your data. If top_n is less than 1000, the API call will automatically be carried out. In the case below, we will return the first 10 records from the NFIP Claims data.
```{r, cache = T}
df <- open_fema(data_set = "fimaNfipClaims", top_n = 10)

df
```

If we wanted to limit the columns returned we could do so by passing a character vector of data fields to be included in the returned data frame. The data fields for a given data set can be retrieved using the `fema_data_fields()` function.

```{r, cache = T}
data_fields <- fema_data_fields("fimanfipclaims")

data_fields
```


In this case we will return only the `policyCount` and `floodZone` columns. As can be seen, an id column is always returned even if the select argument is used. 
```{r, cache = T}
df <- open_fema(data_set = "fimaNfipClaims", top_n = 10, select = c("policyCount","floodZone"))

df
```

If we want to limit the rows returned rather than the columns, we can also apply filters by specifying values of the columns to return. If we want to quickly see the set of variables that can be used to filter API queries with, we can use the valid_parameters() function to return a tibble containing the variables that are "searchable" for a particular data set. 
```{r, cache = T}
params <- valid_parameters(data_set = "fimaNfipClaims")

params

```

We can see from the above that both `policyCount` and `floodZone` are both searchable variables. Thus we can specify a list that contains the values of each variable that we want returned. Before doing that however, it can be useful to learn a bit more about each parameter by using the `parameter_values()` function. 

```{r, cache = T}
# get more information onf the "floodZone" parameter from the NFIP Claims data set
parameter_values(data_set = "fimaNfipClaims",data_field = "floodZone")
```

As can be seen `parameter_values()` returns the data set name, the data field (i.e. the searchable parameter), a description of the data field, and a vector of examples of the data field values which can be useful for seeing how the values are formatted in the data. 
```{r, cache = T}
parameter_values(data_set = "fimaNfipClaims",data_field = "floodZone")
```


We can see from the above that `floodZone` is a character in the data and from the description we know that "AE" and "X" are both valid values for the `floodZone` parameter. We can thus define a filter to return only records from AE or X flood zones.
```{r, cache = T}
# construct a filter that limits records to those in AE or X flood zones
my_filters <- list(floodZone = c("AE","X"))

# pass the filter to the open_fema function.
df <- open_fema(data_set = "fimaNfipPolicies", top_n = 10, 
               select = c("policyCount","floodZone"), filters = my_filters)

df


```






## More Examples

### Example: Return the first 100 NFIP claims for Autauga County, AL that happened between 2010 and 2020.
```{r, cache = T}
df <- open_fema(data_set = "fimaNfipClaims",
                 top_n = 100,
                 filters = list(countyCode = "= 01001",
                                yearOfLoss = ">= 2010",
                                yearOfLoss = "<= 2020"))

df
```


### Example: Get data on all Hazard Mitigation Grants associated with Hurricanes in Florida.
```{r, cache = T}
# see which parameter can be used for filtering the Hazard Mitigation Grants data set
valid_parameters("HazardMitigationGrants") 

# see how values of "incidentType" are formatted
parameter_values(data_set = "HazardMitigationGrants", data_field = "incidentType") 

# check to see how "state" is formatted
parameter_values(data_set = "HazardMitigationGrants", data_field = "state") 

# construct a list containing filters for Hurricane and Florida
filter_list <- c(incidentType = c("Hurricane"),
                 state = c("Florida")) 

# pass filter_list to the open_fema function to retreieve data.
df <- open_fema(data_set = "HazardMitigationGrants", filters = filter_list, 
               ask_before_call = FALSE)


df
```


### Example: Determine how much money was awarded by FEMA for rental assistance following Hurricane Irma.

Get a dataset description for the `HousingAssistanceRenters` data set to see if this is the right data set for the question
```{r, cache = T}
# get meta data for the `HousingAssistanceRenters`
ds <- fema_data_sets() %>% filter(name == "HousingAssistanceRenters")

# there are two entries corresponding to two versions of the data set, 
# we want the most recent one
nrow(ds)
ds <- ds %>% filter(version == max(as.numeric(ds$version)))

# now print out the data set description and make sure its the data set 
# that applicable or our research question
print(ds$description)

```

See which columns we can filter on to select just Hurricane Irma related grants
```{r, cache = T}
# see which parameter can be used for filtering the Housing Assistance for Renters 
valid_parameters("HousingAssistanceRenters") 
```

All we have in this data set is the `disasterNumber`. Thus, to filter on a specific disaster we have to load the `FemaWebDisasterDeclarations` data find the disaster number associated with the event we are interested in.
```{r, cache = T}
# call the disaster declarations
dd <- rfema::open_fema(data_set = "FemaWebDisasterDeclarations", ask_before_call = F)

# filter disaster declarations to those with "hurricane" in the name
hurricanes <- distinct(dd %>% filter(grepl("hurricane",tolower(disasterName))) %>% select(disasterName, disasterNumber))
hurricanes


```

We can see immediately that disaster numbers do not uniquely identify an event, since multiple disaster declarations may be declared for the same event, but in different locations. Thus to filter on a particular event, we need to collect all the disaster declaration numbers corresponding to that event (in this case Hurricane Irma). 
```{r, cache = T}
# get all disaster declarations associated with hurricane irma. 
# notice the use of grepl() which picked up a disaster declaration name 
# that was different than all the others.
dd_irma <- hurricanes %>% filter(grepl("irma",tolower(disasterName)))
dd_irma

# get a vector of just the disaster declaration numbers
dd_nums_irma <- dd_irma$disasterNumber

```

Now we are read to filter our API call for the `HousingAssistanceRenters` data set.
```{r, cache = T}
# construct filter list
filter_list <- list(disasterNumber = dd_nums_irma)


# make the API call to get individual assistance grants awarded to renters for hurricane Irma damages.
assistance_irma <- open_fema(data_set = "HousingAssistanceRenters", filters = filter_list, ask_before_call = F)

```

Check out the returned data
```{r, cache = T}
# check out the returned data
assistance_irma
```


Now we can answer our original question: How much did FEMA awarded for rental assistance following Hurricane Irma?
```{r, cache = T}
# sum the rentalAmount Column
rent_assistance <- sum(as.numeric(assistance_irma$rentalAmount))

# scale to millions
rent_assistance <- rent_assistance/1000000

print(paste0("$",round(rent_assistance,2),
             " million was awarded by FEMA for rental assistance following Hurricane Irma"))

```



## Bulk Downloads
In some cases bulk downloading a full data set file may be preferred. For particularly large data requests, its usually faster to bulk download the entire data set as a csv file and then load it into the R environment. In this case, users can use the bulk_dl() command to download a csv of the full data file and save it to a specified directory.
```{r,cache = T,message = F, warning = F}
bulk_dl("femaRegions") # download a csv file containing all info on FEMA regions
```

```{r,cache = F, include = F}
file.remove("FemaRegions.csv")
```
